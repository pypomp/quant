==== 25-06-13 ==== greatlakes ====

2025-06-13 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 1000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 4.3813 s,  pre-jitted 1.7389 s (sd 0.006 ) 
pfilter: with jit 2.6672 s,  pre-jitted 0.5723 s (sd 0.0104 )

2025-06-13 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 2000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 6.7759 s,  pre-jitted 3.2031 s (sd 0.0094 ) 
pfilter: with jit 4.2028 s,  pre-jitted 1.1293 s (sd 0.0103 )

2025-06-13 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 5000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 12.5301 s,  pre-jitted 5.6641 s (sd 0.0159 ) 
pfilter: with jit 8.6885 s,  pre-jitted 2.5563 s (sd 0.0083 )

2025-06-13 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 10000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 22.0822 s,  pre-jitted 9.0664 s (sd 0.0576 ) 
pfilter: with jit 15.2367 s,  pre-jitted 3.7352 s (sd 0.0386 )

  == and on gpu == the timing here seems implausible ==

2025-06-13 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 1000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 8.6543 s,  pre-jitted 2.5784 s (sd 0.1092 ) 
pfilter: with jit 6.9134 s,  pre-jitted 2.628 s (sd 0.065 )

2025-06-13 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 5000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 13.6569 s,  pre-jitted 2.7427 s (sd 0.1006 ) 
pfilter: with jit 11.7993 s,  pre-jitted 2.6526 s (sd 0.0947 )

2025-06-13 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 20000 
Python 3.12.8 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 34.0724 s,  pre-jitted 2.8121 s (sd 0.0969 ) 
pfilter: with jit 31.474 s,  pre-jitted 2.6498 s (sd 0.0647 )


==== 25-06-11 ==== ed's mac studio ====

Note: previous results suffered from an asynchronous dispatch issue.
To get proper timing, we need to 
use jax.block_until_ready() or make sure that a result
is printed, or written to file, to ensure the object is
fully evaluated before the timer is ended. The latter was
experimentally more reliable, and that is
what is now done in test.py

2025-06-11 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.1.1 for dacca with J = 10000 
Python 3.12.9 , jax 0.6.1 , jaxlib 0.6.1 
pfilter: with jit 6.859637 s,  pre-jitted 1.782041 s 

Comare with R-pomp pfilter
         J dacca_time
[1,]   500      0.525
[2,]  1000      0.991
[3,]  2000      1.957
[4,]  5000      4.896
[5,] 10000      9.753

Here, pypomp is run on 10 processors, and has a roughly factor of 5 improvement. i.e., there is a factor of 2 cost to parallelization. 

Given that R-pomp is quite efficient, this is arguably a reasonable result.

The real advantage is ability to accelerate on GPUs.




==== 25-05-29 ==== kunyang's gpu ====

2025-05-29 pypomp speed test using [CpuDevice(id=0)]
pypomp 0.0.13 for dacca with J = 1000
Python 3.12.4 , jax 0.6.1 , jaxlib 0.6.1
mif: with jit 1.621762 s, pre-jitted 0.006476 s
pfilter: with jit 1.464777 s, pre-jitted 0.06918 s

2025-05-29 pypomp speed test using [CpuDevice(id=0)]
pypomp 0.0.13 for dacca with J = 10000
Python 3.12.4 , jax 0.6.1 , jaxlib 0.6.1
mif: with jit 7.624655 s, pre-jitted 0.007149 s
pfilter: with jit 8.559116 s, pre-jitted 2.798513 s

2025-05-29 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.0.13 for dacca with J = 1000 
Python 3.10.12 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 3.549827 s,  pre-jitted 0.524411 s 
pfilter: with jit 2.71455 s,  pre-jitted 0.564133 s

2025-05-29 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.0.13 for dacca with J = 10000 
Python 3.10.12 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 10.191088 s,  pre-jitted 0.565054 s 
pfilter: with jit 9.706278 s,  pre-jitted 0.541375 s 

2025-05-29 pypomp speed test using [CudaDevice(id=0)] 
pypomp 0.0.13 for dacca with J = 50000 
Python 3.10.12 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 40.501598 s,  pre-jitted 0.673799 s 
pfilter: with jit 39.661828 s,  pre-jitted 0.558186 s

==== 25-05-28 ==== ed's mac studio ====

2025-05-28 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.0.13 for dacca with J = 1000 
Python 3.12.9 , jax 0.5.3 , jaxlib 0.5.3 
mif: with jit 1.246296 s,  pre-jitted 0.00158 s 
pfilter: with jit 0.915628 s,  pre-jitted 0.876334 s 

and, after upgrading jax,

2025-05-28 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.0.13 for dacca with J = 1000 
Python 3.12.9 , jax 0.6.1 , jaxlib 0.6.1 
mif: with jit 1.304215 s,  pre-jitted 0.001539 s 
pfilter: with jit 1.005107 s,  pre-jitted 0.8244

==== 25-05-24 ==== bo's gpu ====

For windows system: JAX does not support NVIDIA GPU under Windows framework. 2. For the Linux system on my desktop: the elapsed1 was around 23s and elapsed2 was around 0.36s with CUDA version 12.3.0.

==== 25-05-23 ==== greatlakes cpu ====

2025-05-23 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.0.9 for dacca with J = 1000 
mif: with jit 28.267137 s,  pre-jitted 0.002305 s 
pfilter: with jit 55.952986 s,  pre-jitted 0.001007 s 

====  25-05-23 ==== mac ====

2025-05-23 pypomp speed test using [CpuDevice(id=0)] 
pypomp 0.0.11 for dacca with J = 1000 
mif: with jit 8.583893 s,  pre-jitted 0.002077 s 
pfilter: with jit 8.657528 s,  pre-jitted 0.001038 s 



==== 25-05-23 ==== greatlakes gpu ====

salloc --account=ionides1 --partition=gpu --gpus=v100:1 --cpus-per-gpu=2 --mem=16000
module load python
module load cuda/12.3.0
# use python environment set up with
# python -m venv ~/opt/py3.12
source ~/opt/py3.12/bin/activate
pip install ~/git/pypomp

then ran report.py from the Python prompt:
import report

# >>> report.elapsed1
# 66.37775782682002
# >>> report.elapsed2
# 0.25251244008541107
# >>> report.elapsed3
# 66.6533479783684
# >>> report.elapsed4
# 0.2569975256919861

This is far too slow.

==== 25-05-22 ==== kevin's gpu ====

>>> elapsed1
7.07886975700967
>>> elapsed2
0.0008318440231960267
>>> elapsed3
6.5981464450014755
>>> elapsed4
0.0002133459784090519

==== ==== ====
